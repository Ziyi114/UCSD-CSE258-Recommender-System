{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "8fadc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import numpy\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "0e39c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will suppress any warnings, comment out if you'd like to preserve them\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "bcdcf1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check formatting of submissions\n",
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "42a8d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "84568759",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"spoilers.json.gz\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "d4b15a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for l in f:\n",
    "    d = eval(l)\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "043724ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "23147241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few utility data structures\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "\n",
    "for d in dataset:\n",
    "    u,i = d['user_id'],d['book_id']\n",
    "    reviewsPerUser[u].append(d)\n",
    "    reviewsPerItem[i].append(d)\n",
    "\n",
    "# Sort reviews per user by timestamp\n",
    "for u in reviewsPerUser:\n",
    "    reviewsPerUser[u].sort(key=lambda x: x['timestamp'])\n",
    "    \n",
    "# Same for reviews per item\n",
    "for i in reviewsPerItem:\n",
    "    reviewsPerItem[i].sort(key=lambda x: x['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "742587d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2012-03-13',\n",
       " '2013-05-06',\n",
       " '2013-09-03',\n",
       " '2015-04-05',\n",
       " '2016-02-10',\n",
       " '2016-05-29']"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E.g. reviews for this user are sorted from earliest to most recent\n",
    "[d['timestamp'] for d in reviewsPerUser['b0d7e561ca59e313b728dc30a5b1862e']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "e33ef573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': 'b0d7e561ca59e313b728dc30a5b1862e',\n",
       " 'timestamp': '2013-05-06',\n",
       " 'review_sentences': [[0,\n",
       "   'The author did an excellent job of making a very readable novel about the emotional lives of Hadley and Ernest Hemingway.'],\n",
       "  [0,\n",
       "   'The many other creative people interacting with them in Paris in the 1920s were very colorful and interesting too.'],\n",
       "  [0,\n",
       "   'She captured a wonderful snapshot of the 1920s in Europe--the men returning from war, the writing, the music, the art, the fashions, the eating and drinking.'],\n",
       "  [0,\n",
       "   'Mostly told from the viewpoint of Hadley, the book shows she was very attracted to Ernest who was extroverted, interesting, ambitious, and a gifted writer.'],\n",
       "  [0,\n",
       "   'Hadley had a sweetness, and more traditional values than some of their friends in Paris.'],\n",
       "  [0,\n",
       "   'They both came from families with domineering mothers and suicidal fathers.'],\n",
       "  [0,\n",
       "   'Ernest was still suffering the traumatic effects of his time in World War I. He was also very self absorbed, and hurt Hadley very deeply.'],\n",
       "  [0, 'Their love story spiraled downward as his career took off.'],\n",
       "  [0,\n",
       "   'I enjoyed this historical fiction about the five years of their marriage, and was sorry to see the book end.'],\n",
       "  [0, 'First read August 3, 2011'],\n",
       "  [0, 'Reread May 7, 2013 for a bookgroup']],\n",
       " 'rating': 4,\n",
       " 'has_spoiler': False,\n",
       " 'book_id': '8683812',\n",
       " 'review_id': 'd293fbf3512a0b05faffec43a7811c55'}"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "213c21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "bb364612",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "448f6d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 4, 4, 4, 4], [3, 4], [4, 3, 4, 5, 2, 4, 3, 5], [5], [5, 2, 3, 5, 5, 5], [3, 5, 5, 4], [4], [5, 4, 5, 5, 5, 5, 4, 5], [4, 3, 3, 5, 0, 4, 5, 4, 4, 3, 4, 0, 5], [4, 3, 4, 3, 5, 5, 5, 4, 3, 3]]\n",
      "[3, 4, 4, 5, 4, 5, 4, 4, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for key in reviewsPerUser:\n",
    "    if len(reviewsPerUser[key])==1:\n",
    "        continue\n",
    "    tmp=[]\n",
    "    for i in range(len(reviewsPerUser[key])-1):\n",
    "        tmp.append(reviewsPerUser[key][i]['rating'])\n",
    "    x.append(tmp)\n",
    "    y.append(reviewsPerUser[key][-1]['rating'])\n",
    "print(x[:10])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "991fbe6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred=[sum(i)/len(i) for i in x]\n",
    "len(y)==len(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "be9c6893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9704162943957526"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MSE=mean_squared_error()\n",
    "MSE=mean_squared_error\n",
    "MSE(y,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94257a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "373cff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1a'] = MSE(y,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "bcd5ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q1a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "c38c9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "5131368a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 3, 3], [3, 4, 2], [5, 4, 5, 5, 4, 4], [4, 2], [5, 0, 5, 4, 2, 5, 4, 4, 3, 5, 5, 0, 4, 3, 4, 4, 4, 5, 0, 4, 4], [3, 4, 5, 5, 4, 4, 5, 4, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 4, 4, 5, 3], [5, 2, 3, 5, 4, 3, 4, 3, 4, 2, 3, 3, 4, 3, 1, 5, 4], [5, 4, 5, 5, 5, 4, 4, 4, 2, 4, 5, 5, 4, 3, 4, 4, 4, 3, 4], [2, 4, 2, 3, 4, 2, 4, 2, 3], [0, 0, 5, 5, 4, 2, 5, 4, 5, 4, 4, 4, 5, 3, 4, 3]]\n",
      "[0, 5, 2, 5, 5, 3, 4, 4, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for key in reviewsPerItem:\n",
    "    if len(reviewsPerItem[key])==1:\n",
    "        continue\n",
    "    tmp=[]\n",
    "    for i in range(len(reviewsPerItem[key])-1):\n",
    "        tmp.append(reviewsPerItem[key][i]['rating'])\n",
    "    x.append(tmp)\n",
    "    y.append(reviewsPerItem[key][-1]['rating'])\n",
    "print(x[:10])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "0043b188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred=[sum(i)/len(i) for i in x]\n",
    "len(y)==len(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "86348058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.05196610339507"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE=mean_squared_error\n",
    "MSE(y,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "2cccbe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1b'] = MSE(y,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "7288fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q1b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "0abf5752",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "d799ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(N):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    ypred=[]\n",
    "    for key in reviewsPerUser:\n",
    "        if len(reviewsPerUser[key])==1:\n",
    "            continue\n",
    "        tmp=[]\n",
    "        for i in range(len(reviewsPerUser[key])):\n",
    "            tmp.append(reviewsPerUser[key][i]['rating'])\n",
    "        \n",
    "        y.append(reviewsPerUser[key][-1]['rating'])\n",
    "        if len(reviewsPerUser[key]):\n",
    "            x.append(tmp[-N-1:-1])\n",
    "        else:\n",
    "            ave=sum(tmp)/len(tmp)\n",
    "            while len(tmp)<N:\n",
    "                tmp.append(ave)\n",
    "            x.append(tmp)\n",
    "        assert y[-1]==tmp[-1]\n",
    "        assert len(x[0])==N\n",
    "    ypred=[sum(i)/len(i) for i in x]\n",
    "    #print(x[:10])\n",
    "    #print(y[:10])\n",
    "    #print(len(y))\n",
    "    return [y,ypred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "688a35b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,j=experiment(3)\n",
    "len(i)==len(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "538b7d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 4, 5, 4, 5, 4, 4, 4, 0]\n",
      "[4.0, 3.5, 4.0, 5.0, 5.0, 4.666666666666667, 4.0, 4.666666666666667, 3.0, 3.3333333333333335]\n"
     ]
    }
   ],
   "source": [
    "print(i[:10])\n",
    "print(j[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "de6bec47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4916666666666667"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(i[:10],j[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8598f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "bcd540f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = []\n",
    "\n",
    "for N in [1,2,3]:\n",
    "    # etc.\n",
    "    y,ypred=experiment(N)\n",
    "    answers['Q2'].append(MSE(y,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "e3d6d9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.666035950804163, 2.1542691579943236, 2.0280931357090295]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "e1b4ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q2'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "206c058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "3ddd5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature3(N, u): # For a user u and a window size of N\n",
    "    feature=[1]\n",
    "    for i in range(2,N+2):\n",
    "        feature.append(reviewsPerUser[u][-i]['rating'])\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "05e622a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3a'] = [feature3(2,dataset[0]['user_id']), feature3(3,dataset[0]['user_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "f839c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q3a']) == 2\n",
    "assert len(answers['Q3a'][0]) == 3\n",
    "assert len(answers['Q3a'][1]) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "55691b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "d2859c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment3(N):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    ypred=[]\n",
    "    for key in reviewsPerUser:\n",
    "        if len(reviewsPerUser[key])<N+1:\n",
    "            continue\n",
    "        x.append(feature3(N,key))\n",
    "        y.append(reviewsPerUser[key][-1]['rating'])\n",
    "        #assert y[-1]==tmp[-1]\n",
    "    #ypred=[sum(i[-N:])/len(i[-N:]) for i in x]\n",
    "    \n",
    "    return [x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "1c9ec7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315ded95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "4146d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3b'] = []\n",
    "\n",
    "for N in [1,2,3]:\n",
    "    # etc.\n",
    "    x,y=experiment3(N)\n",
    "    lr.fit(x,y)\n",
    "    ypred=lr.predict(x)\n",
    "    mse=MSE(y,ypred)\n",
    "    answers['Q3b'].append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "8563e0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5608319121482543, 1.5409512373315701, 1.5396484853948416]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q3b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "d512b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q3b'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "1ba65fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "4aab34e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "globalAverage = [d['rating'] for d in dataset]\n",
    "globalAverage = sum(globalAverage) / len(globalAverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "2676be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureMeanValue(N, u): # For a user u and a window size of N\n",
    "    feature=[1]\n",
    "    n=len(reviewsPerUser[u])\n",
    "    for i in range(2,N+2):\n",
    "        if i>n:\n",
    "            if n==1:\n",
    "                feature.append(globalAverage)\n",
    "            else:\n",
    "                feature.append(sum(feature[1:n])/len(feature[1:n]))\n",
    "        else:\n",
    "            feature.append(reviewsPerUser[u][-i]['rating'])\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "270cf89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureMissingValue(N, u):\n",
    "    feature=[1]\n",
    "    for i in range(2,N+2):\n",
    "        if i>len(reviewsPerUser[u]):\n",
    "            feature.append(1)\n",
    "            feature.append(0)\n",
    "        else:\n",
    "            feature.append(0)\n",
    "            feature.append(reviewsPerUser[u][-i]['rating'])\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "58791bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q4a'] = [featureMeanValue(10, dataset[0]['user_id']), featureMissingValue(10, dataset[0]['user_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "aa678f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4, 4, 4, 4, 5, 4.2, 4.2, 4.2, 4.2, 4.2],\n",
       " [1, 0, 4, 0, 4, 0, 4, 0, 4, 0, 5, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q4a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "a3c28e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q4a']) == 2\n",
    "assert len(answers['Q4a'][0]) == 11\n",
    "assert len(answers['Q4a'][1]) == 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "cbcee03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "27551fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for key in reviewsPerUser:\n",
    "    if len(reviewsPerUser[key])==1:\n",
    "        continue\n",
    "    tmp=[]\n",
    "    for i in range(len(reviewsPerUser[key])-1):\n",
    "        tmp.append(reviewsPerUser[key][i]['rating'])\n",
    "    x.append(tmp)\n",
    "    y.append(reviewsPerUser[key][-1]['rating'])\n",
    "ypred=[sum(i)/len(i) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "f95cfa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "73fabbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q4b'] = []\n",
    "\n",
    "for featFunc in [featureMeanValue, featureMissingValue]:\n",
    "    # etc.\n",
    "    x=[featFunc(N,u) for u in reviewsPerUser]\n",
    "    y=[reviewsPerUser[u][-1]['rating'] for u in reviewsPerUser]\n",
    "    lr.fit(x,y)\n",
    "    ypred=lr.predict(x)\n",
    "    mse=MSE(y,ypred)\n",
    "    answers['Q4b'].append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "8cd13f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5480131297119455, 1.5354064599216093]"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q4b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "e348489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers[\"Q4b\"], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "c548e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "648d49fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': 'b0d7e561ca59e313b728dc30a5b1862e',\n",
       " 'timestamp': '2013-05-06',\n",
       " 'review_sentences': [[0,\n",
       "   'The author did an excellent job of making a very readable novel about the emotional lives of Hadley and Ernest Hemingway.'],\n",
       "  [0,\n",
       "   'The many other creative people interacting with them in Paris in the 1920s were very colorful and interesting too.'],\n",
       "  [0,\n",
       "   'She captured a wonderful snapshot of the 1920s in Europe--the men returning from war, the writing, the music, the art, the fashions, the eating and drinking.'],\n",
       "  [0,\n",
       "   'Mostly told from the viewpoint of Hadley, the book shows she was very attracted to Ernest who was extroverted, interesting, ambitious, and a gifted writer.'],\n",
       "  [0,\n",
       "   'Hadley had a sweetness, and more traditional values than some of their friends in Paris.'],\n",
       "  [0,\n",
       "   'They both came from families with domineering mothers and suicidal fathers.'],\n",
       "  [0,\n",
       "   'Ernest was still suffering the traumatic effects of his time in World War I. He was also very self absorbed, and hurt Hadley very deeply.'],\n",
       "  [0, 'Their love story spiraled downward as his career took off.'],\n",
       "  [0,\n",
       "   'I enjoyed this historical fiction about the five years of their marriage, and was sorry to see the book end.'],\n",
       "  [0, 'First read August 3, 2011'],\n",
       "  [0, 'Reread May 7, 2013 for a bookgroup']],\n",
       " 'rating': 4,\n",
       " 'has_spoiler': False,\n",
       " 'book_id': '8683812',\n",
       " 'review_id': 'd293fbf3512a0b05faffec43a7811c55'}"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "1cee7eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature5(sentence):\n",
    "    feature=[]\n",
    "    f1=len(sentence)\n",
    "    f2=sentence.count('!')\n",
    "    f3=0\n",
    "    for s in sentence:\n",
    "        if 0<=ord(s)-ord('A')<26:\n",
    "            f3+=1\n",
    "    feature=[1,f1,f2,f3]\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "426ca2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "X = []\n",
    "\n",
    "for d in dataset:\n",
    "    for spoiler,sentence in d['review_sentences']:\n",
    "        X.append(feature5(sentence))\n",
    "        y.append(spoiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "428bd0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 121, 0, 4]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "a94d7aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5a'] = X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "e9edcfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "Lr=LogisticRegression(class_weight='balanced',C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "c8ade583",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lr.fit(X,y)\n",
    "y_pre=Lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "f9efaff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_mat=confusion_matrix(y,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "6e583a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP=coef_mat[0][0],coef_mat[0][1]\n",
    "FN, TP=coef_mat[1][0],coef_mat[1][1]\n",
    "def get_ber(TP,TN,FP,FN):\n",
    "    return (FP/(FP+TN)+FN/(FN+TP))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "86727a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.470265288006232"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BER=get_ber(TP,TN,FP,FN)\n",
    "BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "116c5b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5b'] = [TP, TN, FP, FN, BER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "c0c96525",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q5a']) == 4\n",
    "assertFloatList(answers['Q5b'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "f826e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "193e94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature6(review):\n",
    "    sentences=d['review_sentences']\n",
    "    feature=[sentences[0][0],sentences[1][0],sentences[2][0],sentences[3][0],sentences[4][0]]\n",
    "    sentence=sentences[5][1]\n",
    "    f0=1\n",
    "    f1=len(sentence)\n",
    "    f2=sentence.count('!')\n",
    "    f3=0\n",
    "    for s in sentence:\n",
    "        if 0<=ord(s)-ord('A')<26:\n",
    "            f3+=1\n",
    "    feature=[1,f1,f2,f3]+feature\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "0a437dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "X = []\n",
    "\n",
    "for d in dataset:\n",
    "    sentences = d['review_sentences']\n",
    "    if len(sentences) < 6: continue\n",
    "    X.append(feature6(d))\n",
    "    y.append(sentences[5][0])\n",
    "\n",
    "#etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "c61a5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6a'] = X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "7ab45177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17054998141954664"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lr.fit(X,y)\n",
    "y_pre=Lr.predict(X)\n",
    "coef_mat=confusion_matrix(y,y_pre)\n",
    "TN, FP=coef_mat[0][0],coef_mat[0][1]\n",
    "FN, TP=coef_mat[1][0],coef_mat[1][1]\n",
    "BER=get_ber(TP,TN,FP,FN)\n",
    "BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "f977c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6b'] = BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "f0be28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(answers['Q6a']) == 9\n",
    "assertFloat(answers['Q6b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "3bda0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "8c01c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50/25/25% train/valid/test split\n",
    "Xtrain, Xvalid, Xtest = X[:len(X)//2], X[len(X)//2:(3*len(X))//4], X[(3*len(X))//4:]\n",
    "ytrain, yvalid, ytest = y[:len(X)//2], y[len(X)//2:(3*len(X))//4], y[(3*len(X))//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "c253fc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13345081097468545,\n",
       " 0.1331097468546309,\n",
       " 0.143027133545551,\n",
       " 0.14268606942549644,\n",
       " 0.14268606942549644]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bers=[]\n",
    "for c in [0.01, 0.1, 1, 10, 100]:\n",
    "    # etc.\n",
    "    Lr=LogisticRegression(class_weight='balanced',C=c)\n",
    "    Lr.fit(Xtrain,ytrain)\n",
    "    y_pre=Lr.predict(Xvalid)\n",
    "    coef_mat=confusion_matrix(yvalid,y_pre)\n",
    "    TN, FP=coef_mat[0][0],coef_mat[0][1]\n",
    "    FN, TP=coef_mat[1][0],coef_mat[1][1]\n",
    "    BER=get_ber(TP,TN,FP,FN)\n",
    "    bers.append(BER)\n",
    "bers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "4455bc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestber=min(bers)\n",
    "bestC=[0.01, 0.1, 1, 10, 100][bers.index(bestber)]\n",
    "bestC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "f3143417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21333748810528996"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lr=LogisticRegression(class_weight='balanced',C=bestC)\n",
    "Lr.fit(Xtrain,ytrain)\n",
    "y_pre=Lr.predict(Xtest)\n",
    "coef_mat=confusion_matrix(ytest,y_pre)\n",
    "TN, FP=coef_mat[0][0],coef_mat[0][1]\n",
    "FN, TP=coef_mat[1][0],coef_mat[1][1]\n",
    "ber=get_ber(TP,TN,FP,FN)\n",
    "ber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "b8389608",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q7'] = bers + [bestC] + [ber]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "1d53b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q7'], 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "f06e4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "38a6c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "57f30ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75/25% train/test split\n",
    "dataTrain = dataset[:15000]\n",
    "dataTest = dataset[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "1d770bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few utilities\n",
    "\n",
    "itemAverages = defaultdict(list)\n",
    "ratingMean = []\n",
    "\n",
    "for d in dataTrain:\n",
    "    itemAverages[d['book_id']].append(d['rating'])\n",
    "    ratingMean.append(d['rating'])\n",
    "\n",
    "for i in itemAverages:\n",
    "    itemAverages[i] = sum(itemAverages[i]) / len(itemAverages[i])\n",
    "\n",
    "ratingMean = sum(ratingMean) / len(ratingMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "62952595",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "usersPerItem = defaultdict(set)\n",
    "\n",
    "for d in dataTrain:\n",
    "    u,i = d['user_id'], d['book_id']\n",
    "    reviewsPerUser[u].append(d)\n",
    "    usersPerItem[i].add(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "4e0ab533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From my HW2 solution, welcome to reuse\n",
    "def predictRating(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['rating'] - itemAverages[i2])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        if item in itemAverages:\n",
    "            return itemAverages[item]\n",
    "        else:\n",
    "            return ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "db0e1d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=[d['rating'] for d in dataTest]\n",
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "4c0e7355",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[predictRating(d['user_id'],d['book_id']) for d in dataTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "e4891766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.816493441279133"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[\"Q8\"] = MSE(predictions, labels)\n",
    "answers['Q8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "789b53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers[\"Q8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "0b298ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "5930c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[d['rating'] for d in dataTest]\n",
    "predictions=[predictRating(d['user_id'],d['book_id']) for d in dataTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "34b1aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "itemAperance=defaultdict(int)\n",
    "for d in dataTrain:\n",
    "    itemAperance[d['book_id']]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "5e095b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 2860 1780\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "pos_never=[]\n",
    "pos_1to5=[]\n",
    "pos_5=[]\n",
    "pos=0\n",
    "for d in dataTest:\n",
    "    if 0==itemAperance[d['book_id']]:\n",
    "        pos_never.append(pos)\n",
    "    elif 0<itemAperance[d['book_id']]<=5:\n",
    "        pos_1to5.append(pos)\n",
    "    else:\n",
    "        pos_5.append(pos)\n",
    "    pos+=1\n",
    "lab1,lab2,lab3=[],[],[]\n",
    "pre1,pre2,pre3=[],[],[]\n",
    "\n",
    "for pos in pos_never:\n",
    "    lab1.append(labels[pos])\n",
    "    pre1.append(predictions[pos])\n",
    "    \n",
    "for pos in pos_1to5:\n",
    "    lab2.append(labels[pos])\n",
    "    pre2.append(predictions[pos])\n",
    "    \n",
    "for pos in pos_5:\n",
    "    lab3.append(labels[pos])\n",
    "    pre3.append(predictions[pos])\n",
    "print(str(len(pos_never))+' '+str(len(pos_1to5))+' '+str(len(pos_5)))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "6c5bc046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7420124844444445"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse0=MSE(pre1, lab1)\n",
    "mse0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "d06b1388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0526818720058895"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse1to5=MSE(pre2, lab2)\n",
    "mse1to5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "b33d3f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4520632348645055"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse5=MSE(pre3, lab3)\n",
    "mse5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "d269238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[\"Q9\"] = [mse0, mse1to5, mse5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "ebfff50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers[\"Q9\"], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "0dbe10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa1e5ba",
   "metadata": {},
   "source": [
    "Fistly, I want to improve the rating mean since some ratings could be too emotional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "2ba0f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_newratingMean(c):\n",
    "    new_ratingMean=[]\n",
    "    for d in dataTrain:\n",
    "\n",
    "        new_ratingMean.append(d['rating'])\n",
    "    n=len(new_ratingMean)\n",
    "    new_ratingMean=new_ratingMean[int(n*c):int(n*(1-c))]\n",
    "\n",
    "    new_ratingMean = sum(new_ratingMean) / len(new_ratingMean)\n",
    "    return new_ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "1edfa07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7414435395225092"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=[]\n",
    "for i in range(1,21):\n",
    "    new_ratingMean=get_newratingMean(0.01*i)\n",
    "    arr=[new_ratingMean]*len(lab1)\n",
    "    result.append(MSE(lab1,arr))\n",
    "best=min(result)\n",
    "print(result.index(best))\n",
    "result[result.index(best)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "a773491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "itsMSE=result[result.index(best)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "ddf6ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingMean=new_ratingMean=get_newratingMean(0.01*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a823d8bd",
   "metadata": {},
   "source": [
    "Secondly, improve the model by giving predictions based on users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "20f652a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "userAverages=defaultdict(list)\n",
    "for d in dataTrain:\n",
    "    userAverages[d['user_id']].append(d['rating'])\n",
    "    \n",
    "for u in userAverages:\n",
    "    userAverages[u] = sum(userAverages[u]) / len(userAverages[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "9c2c06ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRating(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['rating'] - itemAverages[i2])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        if item in itemAverages:\n",
    "            return itemAverages[item]\n",
    "        elif user in userAverages:\n",
    "            return userAverages[user]\n",
    "        else:\n",
    "            return ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "29d046a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[predictRating(d['user_id'],d['book_id']) for d in dataTest if 0==itemAperance[d['book_id']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "b15bb14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)==len(lab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "941b9c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6697016035547483"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(predictions,lab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "a52b4d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "itsMSE=MSE(predictions,lab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "305d3531",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[\"Q10\"] = (\"As we know that if the item didn't show in \\\n",
    "the train set, then we use the mean rating of the train set to make predictions.\\\n",
    "My idea has two steps.The first is that some ratings could be useless since they could be too\\\n",
    "emotional. That is to say some users may be too satisfied that gave a 5 or too depressed and gave a 1.\\\n",
    "Both of them could be useless either higher than the product should be or too lower.\\\n",
    "So I managed to choose a range to get rid of the a portion of lowest and highest ratings.\\\n",
    "I used a for loop to compare and choose a best range, and seems get a small improvement.\\\n",
    "Secondly, just give a mean is too rough, we give r(u,i) based on u and i, and mean idea ignores the\\\n",
    "importance of user. So if item didn't show in train set but user did, we can make predictions\\\n",
    "based on history of user. So there is huge improvement. The only first step improves to 1.72144, which is close to\\\n",
    "original one. With step 2 and 1 together, the model preforms better with MSE of around 1.67.\\\n",
    "\", itsMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "d0613500",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(answers[\"Q10\"][0]) == str\n",
    "assertFloat(answers[\"Q10\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "436d2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_midterm.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53acc41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
